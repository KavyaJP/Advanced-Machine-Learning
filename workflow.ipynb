{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81731e6d",
   "metadata": {},
   "source": [
    "# Title: ABC\n",
    "\n",
    "Problem Statement (What we are predicting/clustering?)\n",
    "\n",
    "Type of Machine Learning (Regression/Classification/Clustering)\n",
    "\n",
    "Success Metrices (RMSE, R2, Accuracy, Precision, Recall etc.)\n",
    "\n",
    "Constraints or Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe10423",
   "metadata": {},
   "source": [
    "## Enviroment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe110f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa393e",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abf11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('path_to_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c0d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e457b4f2",
   "metadata": {},
   "source": [
    "from the df.shape, write how many features and rows we have in a markdown as a conclusion of this step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d614e50b",
   "metadata": {},
   "source": [
    "## Data Understanding - EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd00fdcb",
   "metadata": {},
   "source": [
    "Basic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654aae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7041bdda",
   "metadata": {},
   "source": [
    "how many null values in each features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8666a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f07966",
   "metadata": {},
   "source": [
    "identifying the numerical columns and categorical columns in our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c4a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = df.select_dtypes(include='number').columns\n",
    "categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "print(f'Numerical Columns: {numerical_columns}')\n",
    "print(f'Categorical Columns: {categorical_columns}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbe9d72",
   "metadata": {},
   "source": [
    "statistical inference of numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d5d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ef9184",
   "metadata": {},
   "source": [
    "### Visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d657cea2",
   "metadata": {},
   "source": [
    "distribution of our target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9039b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df['target_variable'], bins=30, kde=True)\n",
    "plt.title('Distribution of Target Variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46488d4",
   "metadata": {},
   "source": [
    "now let's visualise our categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e20a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_plots(df):\n",
    "    \"\"\"\n",
    "    Plots:\n",
    "    1. Pie charts for all categorical columns\n",
    "    2. Histograms for all numerical columns\n",
    "    3. Boxplots for all numerical columns\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    numerical_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "    # -----------------------------\n",
    "    # Pie Charts (Categorical)\n",
    "    # -----------------------------\n",
    "    if len(categorical_cols) > 0:\n",
    "        n_cols = 3\n",
    "        n_rows = math.ceil(len(categorical_cols) / n_cols)\n",
    "\n",
    "        plt.figure(figsize=(5 * n_cols, 5 * n_rows))\n",
    "        for i, col in enumerate(categorical_cols, 1):\n",
    "            plt.subplot(n_rows, n_cols, i)\n",
    "            values = df[col].value_counts()\n",
    "            top = values.head(5)\n",
    "            if len(values) > 5:\n",
    "                others = values[5:].sum()\n",
    "                top['Others'] = others\n",
    "            plt.pie(top, labels=top.index, autopct='%1.1f%%', startangle=140)\n",
    "            plt.ylabel('')\n",
    "            plt.title(f\"distribution of {col}\")\n",
    "\n",
    "        plt.suptitle('Categorical Columns - Pie Charts', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Histograms (Numerical)\n",
    "    # -----------------------------\n",
    "    if len(numerical_cols) > 0:\n",
    "        n_cols = 3\n",
    "        n_rows = math.ceil(len(numerical_cols) / n_cols)\n",
    "\n",
    "        plt.figure(figsize=(5 * n_cols, 4 * n_rows))\n",
    "        for i, col in enumerate(numerical_cols, 1):\n",
    "            plt.subplot(n_rows, n_cols, i)\n",
    "            mean = df[col].mean()\n",
    "            plt.axvline(mean, color='r', linestyle='dashed', linewidth=1)\n",
    "            plt.hist(df[col].dropna(), bins=30)\n",
    "            plt.title(f'Histogram of {col}')\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel('Frequency')\n",
    "\n",
    "        plt.suptitle('Numerical Columns - Histograms', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Boxplots (Numerical)\n",
    "    # -----------------------------\n",
    "    if len(numerical_cols) > 0:\n",
    "        n_cols = 3\n",
    "        n_rows = math.ceil(len(numerical_cols) / n_cols)\n",
    "\n",
    "        plt.figure(figsize=(5 * n_cols, 4 * n_rows))\n",
    "        for i, col in enumerate(numerical_cols, 1):\n",
    "            plt.subplot(n_rows, n_cols, i)\n",
    "            plt.boxplot(df[col].dropna())\n",
    "            plt.title(f'Boxplot of {col}')\n",
    "            plt.ylabel(col)\n",
    "\n",
    "        plt.suptitle('Numerical Columns - Boxplots', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "eda_plots(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f749962e",
   "metadata": {},
   "source": [
    "pairplot of our dataframe to check correlation of each feature with each other feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfacc3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df.select_dtypes(include=\"number\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9ded71",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358e4a7d",
   "metadata": {},
   "source": [
    "first make a copy of our dataframe so that our original dataframe is as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e1d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42951d78",
   "metadata": {},
   "source": [
    "now we have to remove the null values from our data which is very common in a lot of datasets\n",
    "\n",
    "we have two ways to handle null values.\n",
    "\n",
    "1. Drop the null values: do this if you have around 5% of null values as total rows, we have a large dataset, if the missingness isn't related to other features at all, and drop the entire feature if it has too many (> 50% or 70%) null values.\n",
    "2. Impute the null values: do this if you have 5 to 30% of rows are null, the dataset is small, if the missing values are somewhat related to other important features or our target variable.\n",
    "    - there are two ways to impute data:\n",
    "        1. Univariate\n",
    "            - Mean/Median/Mode\n",
    "            - Arbitary value\n",
    "        2. Multivariate\n",
    "            - Regression\n",
    "            - KNN\n",
    "            - Train a machine learning model to handle those values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82adb609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# 1. Drop null values\n",
    "# -------------------\n",
    "df_copy.dropna(inplace=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Univariate imputation for\n",
    "# ----------------------------\n",
    "\n",
    "# numerical columns can be imputed with mean or median\n",
    "for col in numerical_columns:\n",
    "    mean_value = df_copy[col].mean()\n",
    "    median_value = df_copy[col].median()\n",
    "    # You can choose either mean or median for imputation\n",
    "    df_copy[col].fillna(median_value, inplace=True)\n",
    "\n",
    "# categorical columns can be imputed with mode\n",
    "for col in categorical_columns:\n",
    "    mode_value = df_copy[col].mode()[0]\n",
    "    df_copy[col].fillna(mode_value, inplace=True)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 2. Multi-variate imputation using KNN Imputer\n",
    "# ---------------------------------------------\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_copy[numerical_columns] = imputer.fit_transform(df_copy[numerical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0170c233",
   "metadata": {},
   "source": [
    "handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32565efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = df_copy.select_dtypes(include='number').columns\n",
    "\n",
    "for col in numerical_columns:\n",
    "    Q1 = df_copy[col].quantile(0.25)\n",
    "    Q3 = df_copy[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e8c796",
   "metadata": {},
   "source": [
    "encode our categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5b32f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "for col in categorical_columns:\n",
    "    df_copy[col] = le.fit_transform(df_copy[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989a6162",
   "metadata": {},
   "source": [
    "## Feature selection 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b4d4e1",
   "metadata": {},
   "source": [
    "1. if a numeric feature has very low variance then it is probably useless.\n",
    "2. make a heatmap of dataframe and remove features that are highly correlated with each other, weakly correlated with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a13a71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_copy.corr(), annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True, yticklabels=True)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dc74ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['unnecessary_column1', 'unnecessary_column2']\n",
    "df_copy = df_copy.drop(columns = columns_to_drop, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1ac3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_copy.drop('target_variable', axis=1)\n",
    "y = df_copy['target_variable']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336a24a4",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3315a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# also add `stratify=y` if classification problem\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a71aa46",
   "metadata": {},
   "source": [
    "we also do scaling after the splitting so that our test data is scaled differently and our model doesn't know that, so our testing is more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58048cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)\n",
    "\n",
    "print(\"Scaling completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d48df5",
   "metadata": {},
   "source": [
    "## Model training - Base model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d418085",
   "metadata": {},
   "source": [
    "train a very basic model such as linear regression or logistic regression to check your performance on very basic models, the reason is that sometimes basic models don't capture too much variance and can prevent overfitting that is caused on fancier models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c540d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_sc, y_train)\n",
    "y_pred = lr.predict(X_test_sc)\n",
    "print(f\"RMSE: {root_mean_squared_error(y_test, y_pred, squared=False)}\")\n",
    "print(f\"R2: {r2_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81be7c16",
   "metadata": {},
   "source": [
    "## Model training - selecting a model from a range of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc9f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    # for classification\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree Classifier': DecisionTreeClassifier(),\n",
    "    'Random Forest Classifier': RandomForestClassifier(),\n",
    "    'Support Vector Classifier': SVC(),\n",
    "\n",
    "    # for regression\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(),\n",
    "    'Random Forest Regressor': RandomForestRegressor(),\n",
    "    'Support Vector Regressor': SVR()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56928058",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_sc, y_train)\n",
    "    y_pred = model.predict(X_test_sc)\n",
    "\n",
    "    if 'Classifier' in model_name or 'Logistic' in model_name:\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - {model_name}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"{model_name} - RMSE: {root_mean_squared_error(y_test, y_pred, squared=False)}\")\n",
    "        print(f\"{model_name} - R2: {r2_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992c3271",
   "metadata": {},
   "source": [
    "## Feature selection 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f813c5",
   "metadata": {},
   "source": [
    "in this we will perform forward selection or backward elimination to find out the best features for our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c11cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs = SequentialFeatureSelector(\n",
    "    estimator=RandomForestRegressor(random_state=42),\n",
    "    n_features_to_select='auto',\n",
    "    direction='forward',\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "sfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36577d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the selected feature names\n",
    "selected_features = X.columns[sfs.get_support()]\n",
    "print(f'Selected Features: {selected_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08df747",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[selected_features]\n",
    "X_test = X_test[selected_features]\n",
    "\n",
    "print(\"Feature selection completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f303ec8",
   "metadata": {},
   "source": [
    "we will also have to rescale our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ba15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38fae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original number of features: {X.shape[1]}\")\n",
    "print(f\"Reduced number of features after selection: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a99af85",
   "metadata": {},
   "source": [
    "Now pick the model with best performance and we will do another feature selection and hypertune its parameters for optimal performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df0b242",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0fd502",
   "metadata": {},
   "source": [
    "now we will test which hyperparameters are the best for our model and gives us the best performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ff9119",
   "metadata": {},
   "source": [
    "GridSearchCV is used to systematically search for the best hyperparameters of a model using cross-validation and a chosen evaluation metric. but we only use GridSearchCV on small datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6d10af",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearchCV = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=42),\n",
    "    param_grid={\n",
    "        'n_estimators': [50, 100, 200, 300, 400],\n",
    "        'max_depth': [None, 10, 20, 30, 40],\n",
    "        'min_samples_split': [2, 5, 10, 15, 20]\n",
    "    },\n",
    "    scoring='root_mean_squared_error',\n",
    "    cv=5,       # 5-Fold Cross Validation\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2   # Verbosity level\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6ac782",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearchCV.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c0872",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best Parameters: {GridSearchCV.best_params_}\")\n",
    "print(f\"Best RMSE: {abs(GridSearchCV.best_score_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef3af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = GridSearchCV.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test_sc)\n",
    "print(f\"Tuned Model RMSE: {root_mean_squared_error(y_test, y_pred_best, squared=False)}\")\n",
    "print(f\"Tuned Model R2: {r2_score(y_test, y_pred_best)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see why these parameters were chosen\n",
    "\n",
    "results_df = pd.DataFrame(GridSearchCV.cv_results_)\n",
    "\n",
    "results_df = results_df[\n",
    "    [\"params\", \"mean_test_score\", \"std_test_score\", \"rank_test_score\"]\n",
    "].sort_values(\"rank_test_score\")\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27feb0b8",
   "metadata": {},
   "source": [
    "## Make the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5e830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestRegressor(**GridSearchCV.best_params_))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_pipeline = pipeline.predict(X_test)\n",
    "print(f\"Pipeline Model RMSE: {root_mean_squared_error(y_test, y_pred_pipeline, squared=False)}\")\n",
    "print(f\"Pipeline Model R2: {r2_score(y_test, y_pred_pipeline)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfff6c03",
   "metadata": {},
   "source": [
    "## Exporting our best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fcb85e",
   "metadata": {},
   "source": [
    "we export our model so that we can use integrate model in a python backend and use our model for making predictions on live data, this is what the entire training was for.\n",
    "\n",
    "we can export our entire pipeline or model as we seem fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e740ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(pipeline, 'final_model_pipeline.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
